# RAG
# ðŸ§  Alfred Agent with LlamaIndex

This project demonstrates how to build a retrieval-augmented generation (RAG) pipeline using [LlamaIndex](https://www.llamaindex.ai/). The goal is to load and process documents, create embeddings, store them in a vector store, and query them using an LLM-powered agent.

---

## ðŸš€ Features

- Load and chunk documents into semantic nodes
- Generate vector embeddings using Hugging Face models
- Store vectors in a persistent Chroma vector database
- Use LlamaIndex's query engine to retrieve and summarize answers
- Evaluate the quality of responses using built-in LlamaIndex evaluators

---

## ðŸ“‚ Project Structure

you can load your dataset for your purpose
(note that i used locall llm)
